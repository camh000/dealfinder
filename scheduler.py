import time
import logging
from apscheduler.schedulers.blocking import BlockingScheduler
from dotenv import load_dotenv
import sys
import os

load_dotenv("credentials.env")

# Add parent dir to path so EbayScraper is importable
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import EbayScraper

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
log = logging.getLogger(__name__)

GPU_QUERY_LIST = [
    "NVIDIA GTX 9",
    "NVIDIA GTX 10",
    "NVIDIA RTX 20",
    "NVIDIA RTX 30",
    "NVIDIA RTX 40",
    "AMD RX 5000",
    "AMD RX 6000",
    "AMD RX 7000",
]

CPU_QUERY_LIST = [
    "Intel Core i3",
    "Intel Core i5",
    "Intel Core i7",
    "Intel Core i9",
    "AMD Ryzen 3",
    "AMD Ryzen 5",
    "AMD Ryzen 7",
    "AMD Ryzen 9",
]

HDD_QUERY_LIST = [
    "SAS hard drive TB",
    "SATA hard drive TB",
]

def run_scraper():
    log.info("Starting scrape run...")
    common = dict(country='uk', condition='used', listing_type='auction', cache=False)
    for query_list, product_type in [
        (GPU_QUERY_LIST, 'GPU'),
        (CPU_QUERY_LIST, 'CPU'),
        (HDD_QUERY_LIST, 'HDD'),
    ]:
        try:
            log.info(f"Scraping {product_type}...")
            EbayScraper.ScrapeAndUpload(query_list, product_type=product_type, **common)
            log.info(f"{product_type} scrape complete.")
        except Exception as e:
            log.error(f"{product_type} scrape failed: {e}")

if __name__ == "__main__":
    log.info("Scheduler starting â€” running immediately then every 30 minutes.")
    run_scraper()

    scheduler = BlockingScheduler()
    scheduler.add_job(run_scraper, 'interval', minutes=30)
    try:
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        log.info("Scheduler stopped.")
